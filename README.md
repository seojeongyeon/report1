## 차량 지능 기초 Report 1 요약_자동차it융합학과 20183382 서정연
<hr>

### 1.	자율주행 인지에 관련된 3종 이상의 공개 Data Set 조사, 정리
* 1.1 BDD100K
    * 데이터 설명 & 양<Br>
    BBD100K는 최근 UC 버클리 인공 지능 연구 실험실 (BAIR)에서 만든 운전 데이터베이스이다.<br>
BDD100K는 Berkeley Deep Drive의 약자로, 40초의 비디오 시퀀스, 720픽셀 해상도, 초당 30 프레임 고화질로 취득된 100,000개 비디오 시퀀스로 구성된다. 동영상에는 거친 주행 궤적을 보여주기 위해 휴대폰으로 기록 된 GPS/ IMU 정보도 함께 제공된다. 또한 거친 주행 환경 구현, GPS 정보, IMU 데이터 및 타임 스탬프도 포함되어 있다. 녹화된 비디오는 날씨, 흐린 날씨, 맑은 날씨, 안개와 같은 다양한 날씨 조건이 기록되어 있다. 데이터 세트는 낮과 밤이 적절한 비율로 기록되어있고 버스, 신호등, 교통 표지, 사람, 자전거, 트럭, 모터, 자동차, 기차 및 라이더를 위해 10만개 이미지에 주석이 달린 2D 경계박스(Bounding Box)가 포함되어 있다.

    * 데이터 활용 예
        * 차선 표시(lane markings)<br>
        차선 표시는 운전자에게 중요한 도로 지침이다. 또한 GPS 또는 지도에 정확한 글로벌 커버리지가 없을 때 자율 주행 시스템의 주행 방향 및 위치 결정에 중요한 단서이다. BBD 100K는 운전 안내를 위해 100,000 개의 이미지에 여러 유형의 차선 표시 주석을 하였다. 차선 표시를 두가지 유형으로 나눠서 하였는데 이미지에 쉽게 주석 처리하기 위해, 수직 차선은 적색, 평행 차선은 청색으로 구분하였다. 적색 표시 있는 운전 경로와 청색 표시가 있는 대안 운전 경로로 주행 가능 구역을 구분한다. <br><br>
        * 도로 객체 감지(Road Object Detection)<br>
        BDD 100K Data set은 버스, 신호등, 교통 표지, 사람, 자전거, 트럭, 모터, 자동차, 기차 및 라이더를 위해 100,000개 이미지에 주석이 달린 2D Bounding Box가 포함되어 있다. 이 데이터는 도로/ 포장 도로의 보행자 탐지를 위해 사용할 수도 있다. 이를 위해, 현재 Data set에는 85,000개가 넘는 보행자 인스턴스가 있다.<br><br>
        * 운전 가능 지역(Driveable Area)<br>
        마지막으로 BBD 100K는 주행 가능 영역의 세분화 주석도 제공한다. 우리가 도로에서 운전할 수 있는지 여부는 차선 표시와 교통 장치에만 의존하지 않는다. 결국 어떤 영역에서 추진할 수 있는지 이해하는 것이 중요한데 BDD 100K는 운전 가능 지역을 표시할 수 있다. 자아 차량의 궤적에 따라 운전 가능 영역을 직접 운전 가능과 대체 운전 가능의 두 가지 범주로 나누고, 빨간색으로 표시된 직접 운전 가능은 자아 차량이 도로 우선 순위를 가지며 해당 지역에서 계속 운전할 수 있음을 의미하게 한다.  파란색으로 표시된 대체 운전 가능 차량은 자아 차량이 해당 지역에서 운전할 수 있지만 도로 우선 순위가 잠재적으로 다른 차량에 속하므로 주의해야한다는 것을 알 수 있다.
```
참고) https://www.bdd100k.com/
```
<br>

* 1.2  Maperial Street – Level Sequence
    * 데이터 설명 & 양<br>
    MSLS(Maperial Street – Level Sequence)는 전 세계 거리 장면을 이해하기 위한 픽셀 단위 및 인스턴스 별 사람 주석이 포함된 다양한 거리 수준 이미지 Data set이다. 37개 클래스에 대한 추가 인스턴스 별 라벨과 함께 66 개 개체 카테고리에 주석이 달린 25,000개의 고해상도 이미지를 가지고 있다. 이 Data set는 강력한 로컬라이제이션과 효율적인 대규모 3D 재구성을 응용해 lifelong learning의 다양성을 보여주기 위해 설계되었다. 6개 대륙 및 30개의 주요 도시 이미지, 서로 다른 관점의 수백대의 카메라 그리고 9년이라는 기간 동안 모든 계절에 걸쳐 수집한 것임을 강조한다. 모든 이미지는 GPS와 나침반으로 위치를 찾아내며 높은 수준의 속성을 특징으로 한다.<br><br>
    * 데이터 활용 예<br>
        * 교통 표지 Data set<br>
        Mapillary 교통 표지 데이터 세트는 교통 표지를 감지하고 인식하도록 기계를 교육하기위한 세계에서 가장 크고 가장 다양한 공개 교통 표지 DateSet이다. 300 개 이상의 서로 다른 교통 표지 등급이 확인되고 주석이 추가되어 이미지 전체에 320,000 개 이상의 레이블이 지정된 교통 표지가 있다. 데이터 세트의 다양성으로 인해 교통 표지 감지 및 분류에 대한 기존의 대규모 벤치 마크 데이터 세트에 대해 효과적인 전이 학습이 가능하다.<br><br>
        *  street-level sequences Dataset<br>
        6개 대륙의 30 개 도시에 걸쳐 있고, 다양한 계절/날씨 및 일광 조건/다양한 카메라 유형 및 시점/다양한 건축 및 구조 설정/장면에 존재하는 다양한 수준의 동적 개체를 다룬다. 각 이미지에는 추가 연구와 관련된 메타 데이터 및 속성 (원시 GPS 좌표, 캡처 시간, 나침반 각도, 주야간 속성, 보기 방향 (전면, 후면 또는 측면))이 함께 제공된다. MSLS에 대한 교육이 지리적 분포, 계절적 및 시간적 변화, 특히 주야간 변화에서 데이터 세트의 다양성으로 인해 성능을 향상시킨다.
```
참고) https://www.mapillary.com/datasets
```
* 1.3 NuScenes<br>
    * 데이터 설명 & 양<br>
    NuScnes는 Motional (이전의 nuTonomy) 팀이 개발한 자율주행을 위한 대규모 공개 Data set이다. Data set를 위해 교통량이 많고 운전 상황이 매우 까다로운 두 도시인 보스턴과 싱가포르에서 1000 개의 운전 장면을 수집했다. 20초 길이의 장면은 다양하고 흥미로운 운전 기동, 교통 상황 및 예상치 못한 행동을 보여주기 위해 수동으로 선택되었고, nuScenes의 풍부한 복잡성은 장면 당 수십 개의 물체가 있는 도시 지역에서 안전한 운전을 가능하게 하는 방법의 개발을 장려한다.<br><br>
    * 특징<br>
    물체 감지 및 추적과 같은 일반적인 컴퓨터 비전 작업을 용이하게 하기위해 전체 Data set에 대해 2Hz에서 정확한 3D 경계 상자로 23 개의 물체 클래스에 주석을 달았다는 게 특징이다. 또한 가시성, 활동 및 포즈와 같은 객체 수준 속성에 주석을 추가하였다. 전체 Data set에는 약 140 만 개의 카메라 이미지, 390k LIDAR 스윕, 140 만 개의 RADAR 스윕 및 40k 키 프레임의 1.4M 개체 경계 상자가 포함된다. <br><br>
    * 데이터 활용 예<br>
    NuScenes는 nuScenes-lidarseg, 지도, 예측, CAN버스등을 다룰 수 있게 제공해준다. 그 중 지도 Data set를 이용해 각 레이어에 대한 설명, 지도 레이어 내에서 특정 레코드를 검색하고 쿼리하는 방법, 렌더링 방법 및 고급 데이터 탐색을 해볼 수 있다. 
    그 예시로 이진 맵 마스크 레이어 렌더링 하는 모습을 살펴보면, 먼저 NuScenesMap 클래스를 사용하여 여러 맵 레이어를 이진 마스크로 변환하고 Matplotlib 그림에서 렌더링한다. 그리고 난 뒤 위에서 검색 한 맵 마스크를 직접 시각화하면 된다. 
    이 밖에도 지도에 자아 포즈 렌더링을 하거나, 도로망 주변 내비게이션 기능 제공, 어떤 차선이 다른 차선에 연결되어 있는지 효울적으로 쿼리한 레인작업등 Nuscenes Data set로 활용할 수 있다.
<br>
<br>

### 2. 자율주행 인지에 관련된 2종 이상 Open Source 조사, 정리
* 2.1 opencv를 이용한 차선 인지 open source
    * <코드를 이해하는데 필요한 정보><br>
    차선인지를 할 수 있는 open source를 찾아보았다. 코드를 실행하기 앞서 OpenCV라는 라이브러리가 필요했다. 먼저 우분투를 이용하여 openCV를 깔아주었고 코드를 실행하였다.
    * <코드 구성> <br>
    Region_of_interest 함수: 차선 후보 영상으로부터 검출된 에지 영상에서 차선이 검출되는 영역을 차선 진행방향의 일정영역 바닥으로 제한한다.
    <br>
    HoughLinesP 함수, draw_line 함수: HoughLinesP로 검출한 선분으로부터 좌우 차선에 있을 가능성있는 직선들만 따로 뽑아서 좌우 각각 하나의 직선으로 변환한다. (Linear Least-Squares Fitting)

    * <전체 코드><br>
    linerecognition.cpp 참고
    * <실행 결과><br>
    직접 촬영한 동영상이 없어 예시 동영상으로 실행해 본 결과, 원본 영상과 좌우 두개의 직선을 추출한 영상을 합쳐서 색깔로 차선을 표현한 것을 볼 수 있었다.
    * <참고한 코드>
    https://github.com/georgesung/road_lane_line_detection/blob/master/lane_lines.py

* 2.2 Nuscenes open source의 데이터 시각화
    * <코드 구성>
    pdf 참고
    * <실행 결과>
    특정 위치에 대한 지도의 모든 장면을 시각화 할 수 있다.
<br>
<br>

### 3. 2)의 정리한 코드 중 하나 실행해서 결과 확인
2.1번의 차선인지 코드를 실행해보았다. 그전에 내 시스템 환경에서는 opencv 라이브러리가 없었기 때문에 코드를 실행하기 위해서는 opencv를 까는 것이 먼저였다. Opencv 4.2.0과 opencv_contrib(extra modules)를 컴파일하여 ubuntu 18.04에 설치하였다. Opencv 컴파일 전에 필요한 패키지들을 설치하였다. 다음은 설치한 패키지들 목록이다.
* 필요한 패키지<br>

    Build-essential : c/c++ 컴파일러와 관련 라이브러리, make 같은 도구들 포함
    Cmake: 컴파일 옵션이나 빌드된 라이브러리에 포함시킬 OpenCV 모듈 설정등을 위해 필요 
    Pkg-config : 프로그램 컴파일 및 링크시 필요한 라이브러리에 대한 정보를 메타파일(확장자가 .pc인 파일)로부터 가져오는데 사용<br>
    libjpeg-dev, livtiff5-dev, libpng-dev : 특정 포맷의 이미지 파일을 불러오거나 기록하기 위해 필요한 패키지<br>
	libavcodec-dev libavformat-dev libswscale-dev libxvidcore-dev libx264-dev libxine2-dev : 특정 코덱의 비디오 파일을 읽어오거나 기록하기 위해 필요한 패키지<br>
	Video4Linux 패키지 : 리눅스에서 실시간 비디오 캡처를 지원하기 위한 디바이스 드라이버와 API를 포함<br>
    GStreamer : 비디오 스트리밍을 위한 라이브러리<br>
    OpenCV:  최적화를 위해 사용되는 라이브러리들<br>
    python2.7-dev와 python3-dev 패키지: OpenCV-Python 바인딩을 위해 필요한 패키지들<br>
Numpy :  매트릭스 연산등을 빠르게 처리할 수 있어서 OpenCV에서 사용

* 깃헙 주소<br>
https://github.com/seojeongyeon/report1.git







